{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca503e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding average duration of each activity\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"newest_aruba.csv\")\n",
    "newdf=pd.DataFrame(df)\n",
    "\n",
    "#newdf[\"Avg_Duration\"]=\"\"\n",
    "newdf[\"MI\"]=\"\"\n",
    "\n",
    "meandf=newdf.groupby(by=\"Annotation\")[\"Duration\"].mean()\n",
    "meandf\n",
    "newest_df=pd.DataFrame()\n",
    "#newest_df.insert(loc=0, column='Avg_Duration', value=newdf.groupby(by=\"Annotation\")[\"Duration\"].mean())\n",
    "#newest_df.insert(loc=1, column='Annotation', value=sorted(newdf['Annotation'].unique()))\n",
    "\n",
    "\n",
    "#ann=sorted(newdf['Annotation'].unique())\n",
    "#newestdf['Avg_Duration']=newdf.groupby(by=\"Annotation\")[\"Duration\"].mean()\n",
    "#newdf['Avg_Duration']\n",
    "#print(newest_df)\n",
    "newdf.groupby(\"Annotation\")[\"Duration\"].mean()\n",
    "\n",
    "newest_df.insert(loc=0, column='Avg_Duration', value=newdf.groupby(by=\"Annotation\")[\"Duration\"].mean())\n",
    "#newest_df.insert(loc=1, column='Annotation', value=sorted(newdf['Annotation'].unique()))\n",
    "\n",
    "print(newest_df)\n",
    "#newest_df.to_csv(\"new_aruba.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf53cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Frequency of sensors\n",
    "#%%timeit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"newest_aruba.csv\")\n",
    "col=['M003','M002','M007','M004','M005','M018','M019','M015','M016','M020','M017','M009','M013','M031','M021','M012','M014','M008','M006','M030','M010','M026','M022','M028','M027','M029','M023','M025','M001','M024','M011','D001','D002']\n",
    "newdf=df[col]\n",
    "newdf.index=df.Annotation\n",
    "print(newdf)\n",
    "sum_df=newdf.sum(axis='columns',min_count=1)\n",
    "#sum_df.index=newdf.Annotation\n",
    "print(sum_df)\n",
    "final_df=newdf.div(sum_df, axis=0).round(3)\n",
    "print(\"Final :\\n\",final_df)\n",
    "# final_df=final_df.groupby(by=\"Annotation\")[col].mean()\n",
    "# print(final_df)\n",
    "deno=df['Annotation'].value_counts()\n",
    "print(deno)\n",
    "print(\"******\")\n",
    "newest_df=final_df.groupby(by=\"Annotation\")[col].sum(min_count=1)\n",
    "print(newest_df)\n",
    "print(\"+++++++\")\n",
    "f_df=newest_df.div(deno, axis=0).round(2)\n",
    "print(f_df)\n",
    "f_df[col] = f_df[col].replace({0:np.nan})\n",
    "print(f_df)\n",
    "f_df=f_df.stack()\n",
    "print(f_df)\n",
    "f_df.to_csv(\"StackIFreq2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c0042",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preactivity\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "d=pd.read_csv(\"newest_aruba.csv\")\n",
    "df=pd.DataFrame(d)\n",
    "ann=df['Annotation'].unique().tolist()\n",
    "print(ann)\n",
    "\n",
    "\n",
    "df2=pd.DataFrame()\n",
    "df3=pd.DataFrame()\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "# print(len(df))\n",
    "# print(df)\n",
    "\n",
    "for i in range(len(ann)):\n",
    "    pre=[]\n",
    "    for j in range(len(df)):\n",
    "        if df.iloc[j].Annotation==ann[i]:\n",
    "            #print(ann[i],df.iloc[j].Annotation)\n",
    "            pre.append(df.iloc[j].preact)\n",
    "    #print(pre)\n",
    "    unic=Counter(pre)\n",
    "    #print(unic)\n",
    "    df2 = pd.DataFrame.from_records(list(dict(unic).items()), columns=['PreAct','Freq'])\n",
    "    #print(df2)\n",
    "    print(df2)\n",
    "    summation=df2['Freq'].sum()\n",
    "    print(summation)\n",
    "    #df3=pd.DataFrame(df2['Freq'].div(summation,axis=0),columns=['Freq'])\n",
    "    df3=df2['Freq'].div(summation,axis=0)\n",
    "    #df3.columns=['Freq_P']\n",
    "    print(df3)\n",
    "    df2=pd.concat([df2,df3],axis=1)\n",
    "    \n",
    "    df2[\"Annotation\"]=ann[i]\n",
    "    print(df2)\n",
    "    df4=pd.concat([df4,df2],axis=0)\n",
    "    #df4.set_index([ann[i]])\n",
    "    #df2 = df.append(pd.Series(pre, index = [ind]), ignore_index=True)\n",
    "print(df4)\n",
    "df4.to_csv('Train_Preact.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05ce45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shift\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "d=pd.read_csv(\"newest_aruba.csv\")\n",
    "df=pd.DataFrame(d)\n",
    "ann=df['Annotation'].unique().tolist()\n",
    "print(ann)\n",
    "\n",
    "df2=pd.DataFrame()\n",
    "df3=pd.DataFrame()\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "# print(len(df))\n",
    "# print(df)\n",
    "\n",
    "for i in range(len(ann)):\n",
    "    pre=[]\n",
    "    for j in range(len(df)):\n",
    "        if df.iloc[j].Annotation==ann[i]:\n",
    "            #print(ann[i],df.iloc[j].Annotation)\n",
    "            pre.append(df.iloc[j].A_Shift)\n",
    "    print(\"111\")\n",
    "    #print(pre)\n",
    "    unic=Counter(pre)\n",
    "    print(unic)\n",
    "    df2 = pd.DataFrame.from_records(list(dict(unic).items()), columns=['Shift','Freq'])\n",
    "    #print(df2)\n",
    "    print(df2)\n",
    "    summation=df2['Freq'].sum()\n",
    "    print(summation)\n",
    "    #df3=pd.DataFrame(df2['Freq'].div(summation,axis=0),columns=['Freq'])\n",
    "    df3=df2['Freq'].div(summation,axis=0)\n",
    "    #df3.columns=['Freq_P']\n",
    "    print(df3)\n",
    "    df2=pd.concat([df2,df3],axis=1)\n",
    "    \n",
    "    df2[\"Annotation\"]=ann[i]\n",
    "    print(df2)\n",
    "    df4=pd.concat([df4,df2],axis=0)\n",
    "    #df4.set_index([ann[i]])\n",
    "    #df2 = df.append(pd.Series(pre, index = [ind]), ignore_index=True)\n",
    "print(df4)\n",
    "#df4.to_csv('Shift.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a8f918",
   "metadata": {},
   "outputs": [],
   "source": [
    "## SEGMENTATION\n",
    "\n",
    "from owlready2 import *\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import time\n",
    "\n",
    "st=time.time()# get the start time\n",
    "\n",
    "onto = get_ontology(\"dummy_ssn1.owl\").load()\n",
    "\n",
    "default_world.full_text_search_properties.append(comment)\n",
    "\n",
    "data=pd.read_csv(\"Temp6.csv\", usecols=['Time','Sensor'])\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "listt=['Relax','Sleeping','Wash_Dishes','Work','Eating','Respirate','Bed_to_Toilet','Housekeeping']\n",
    "\n",
    "f_df=pd.DataFrame()\n",
    "topK={}\n",
    "preAct=\"\"\n",
    "def startSensor(sen,indx,p):\n",
    "    start=onto.search(type = onto.FeatureOfInterest, hasStartSensor = [sen[0]])  #activity with n as the start sensor\n",
    "    print(\"Activity of Start :\",start)\n",
    "    if indx!=0:\n",
    "        if len(start) == 1:\n",
    "            s_i=indx\n",
    "            A_s_n=start[0]\n",
    "            print(\"Start index : \", s_i)\n",
    "            return s_i,A_s_n\n",
    "        elif len(start)>1:\n",
    "            if start[0]==onto.Work:\n",
    "                s_n=start[0]\n",
    "                print(\"++++onto.\", s_n)\n",
    "            else:\n",
    "                s_n=checkPreAct(start,p)\n",
    "                print(\"Start index : \", indx)\n",
    "            return indx,s_n\n",
    "        else:\n",
    "            return -1,\"null\"\n",
    "    return indx,start[0]\n",
    "\n",
    "def getSubString(l_n,sym):\n",
    "    pos=l_n.find(sym)\n",
    "    \n",
    "    if pos>=0:\n",
    "        s_s=l_n[0:pos]\n",
    "    else: \n",
    "        s_s=l_n\n",
    "    print(s_s)\n",
    "    return s_s\n",
    "\n",
    "def preActivity(Act):\n",
    "    i=0\n",
    "    pre={}\n",
    "    preAct={}\n",
    "    p=\"\"\n",
    "    for s, o in onto.hasPreActivityProb.get_relations():\n",
    "        if(i==57):\n",
    "            break\n",
    "        else:\n",
    "            i=i+1\n",
    "            print(i)\n",
    "            print(\"Activity\", s , \"has Pre Acticity Probability : \", o )\n",
    "            if s!=p:\n",
    "                print(\"******\")\n",
    "                max=0.0\n",
    "            if s in Act:\n",
    "                print([s.name, float(o.name)])\n",
    "                if float(o.name)>max:\n",
    "                    max=float(o.name)\n",
    "                    an=o\n",
    "                pre[s]=an\n",
    "                print(\"PreActivity: \",pre)\n",
    "            p=s\n",
    "            print(p)\n",
    "    print(pre) \n",
    "    for key,value in pre.items():\n",
    "        print(value.__class__)\n",
    "        cl=value.__class__.name\n",
    "        print(\"cllc \",cl)\n",
    "        pos=cl.find('0')\n",
    "        if pos>=0:\n",
    "            s_s=cl[pos+1:]\n",
    "        else: \n",
    "            s_s=cl\n",
    "        print(s_s)\n",
    "        preAct[key]=s_s\n",
    "    return preAct\n",
    "        \n",
    "def checkPreAct(p1,p2):\n",
    "    \n",
    "    ditt=['Meal_Preparation','Eating','Leave_Home','Work','Housekeeping','Sleeping','Bed_to_Toilet' ]\n",
    "    dit2={}\n",
    "#     dit3={}\n",
    "#     dit4={}\n",
    "    \n",
    "    dit=preActivity(p1)\n",
    "#     ditt[onto.Leave_Home]='Meal_Preparation'\n",
    "#     dit2[onto.Leave_Home]='Eating'\n",
    "#     dit3[onto.Leave_Home]='Leave_Home' \n",
    "#     dit4[onto.Leave_Home]='Work'\n",
    "#     dit4[onto.Leave_Home]='Housekeeping'\n",
    "    dit2[onto.Meal_Preparation]='Leave_Home'\n",
    "    for k,v in dit.items():\n",
    "        if k.name=='Meal_Preparation':\n",
    "            for x in listt:\n",
    "                if x==p2 or dit2[k]==p2:\n",
    "                    return k\n",
    "        if k.name=='Leave_Home':\n",
    "            for y in ditt:\n",
    "                if y==p2:\n",
    "                    return k\n",
    "        if v==p2 :\n",
    "            return k\n",
    "    return p2\n",
    "            \n",
    "    \n",
    "\n",
    "def findTopK():\n",
    "    for s, o in onto.hasTopK.get_relations():\n",
    "        print(\"Activity\", s , \"has Top K : \", o )\n",
    "        print([s.name, o.name])\n",
    "        topK[s.name]=int(o.name)\n",
    "        print(topK)\n",
    "    \n",
    "def FreqCheck(Act):\n",
    "    freq=[]\n",
    "    i=0\n",
    "    for s, o in onto.hasFreqProbOf.get_relations():\n",
    "        if(i==90):\n",
    "            break\n",
    "        else:\n",
    "            i=i+1\n",
    "            print(i)\n",
    "            print(\"Activity\", s , \"has Frequency Probability : \", o )\n",
    "            if s==Act :\n",
    "                print([s.name, float(o.name)])\n",
    "                freq.append(o)\n",
    "                print(freq)\n",
    "    print(freq)\n",
    "    j=0\n",
    "    se=[]\n",
    "    dic={}\n",
    "    for a, b in onto.hasSensor.get_relations():\n",
    "        if(j==86):\n",
    "            break\n",
    "        else:\n",
    "            j=j+1\n",
    "            print(j)\n",
    "            print(\"Prob\",a, \"has Sensor : \", b)\n",
    "            for i in freq[len(freq)-topK[Act.name]:] :\n",
    "                if i==a:\n",
    "                    print([float(a.name),b.name])\n",
    "                    se.append(b)\n",
    "                    print(se)\n",
    "                    dic[float(a.name)]=b.name\n",
    "                    print(dic)\n",
    "    print(se)\n",
    "    return dic\n",
    "    \n",
    "def findSensor(s,fr):\n",
    "    for i in fr.values():\n",
    "        if i==s:\n",
    "            print(\"yes i: \",i,\"has sensor: \",i)\n",
    "            return 1\n",
    "    print(\"No i: \",i,\"has no sensor: \",i)\n",
    "    return 0\n",
    " \n",
    "def skipSensor(A,j):\n",
    "    print(\"%%%%%%\")\n",
    "    s=df.iloc[j+1].Sensor\n",
    "    print(\"s : \",s)\n",
    "    sen=default_world.search(comment = FTS(s))   #finding the sensor individual using string annotation search\n",
    "    print(sen)\n",
    "    lo=onto.search(type = onto.Deployment, deployedSystem = [sen[0]])  # location of the sensor\n",
    "    lo_name=lo[0].name   # getting only the location name as a string\n",
    "    print(lo_name)\n",
    "    sen_loc=getSubString(lo_name,'_')\n",
    "    print(\"@@@@\",sen_loc)\n",
    "    \n",
    "    if sen_loc==\"Front\" or sen_loc==\"Back\":\n",
    "        return 1\n",
    "    \n",
    "    Actv=default_world.search(comment = FTS(sen_loc))   #searching for activity with location loc_name\n",
    "    print(\"!!!!AL: \",Actv)\n",
    "    Actv_name=Actv[0].name                    # getting only the activity name as string\n",
    "    print(A)\n",
    "    if A in Actv:\n",
    "        print(\"YES\")\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def segment(start_ind,cut_ind,A_name,t_df):\n",
    "    seg=df[start_ind:cut_ind]\n",
    "    seg.columns=['Time',A_name]\n",
    "    t_df=pd.concat([t_df,seg],axis=1)\n",
    "    return t_df\n",
    "    \n",
    "\n",
    "\n",
    "flag=0\n",
    "Activity_name=\"\"\n",
    "f_list=[]\n",
    "i=0\n",
    "start_index=0\n",
    "findTopK()\n",
    "pAct=\"\"\n",
    "skip_count=0\n",
    "for i in range(len(df)):\n",
    "    \n",
    "    x=df.iloc[i].Sensor\n",
    "    print(\"x : \",x)\n",
    "    \n",
    "    sensor=default_world.search(comment = FTS(x))   #finding the sensor individual using string annotation search\n",
    "    print(sensor)\n",
    "    if i==0:\n",
    "        sensr=sensor\n",
    "        ind=i\n",
    "    #sensr=sensor\n",
    "    if flag==0:\n",
    "        print(\"/////////\")\n",
    "        start_index,Activity=startSensor(sensr,ind,pAct)  #getting the Activity if sensor is the start sensor\n",
    "        print(Activity)\n",
    "        if Activity==\"null\":\n",
    "            sensr=sensor\n",
    "            ind=i\n",
    "            continue\n",
    "        print(\"PreActivity: \",pAct,\" has Activity : \",Activity)\n",
    "        freq_list=FreqCheck(Activity)\n",
    "        Activity_name=Activity.name\n",
    "#         else:\n",
    "#             sensr=sensor\n",
    "#             ind=i\n",
    "#             continue\n",
    "        \n",
    "        \n",
    "    loc=onto.search(type = onto.Deployment, deployedSystem = [sensor[0]])  # location of the sensor\n",
    "    loc_name=loc[0].name   # getting only the location name as a string\n",
    "    \n",
    "    sensor_loc=getSubString(loc_name,'_')\n",
    "    \n",
    "    if sensor_loc==\"Front\" or sensor_loc==\"Back\":\n",
    "        continue\n",
    "    \n",
    "    Act=default_world.search(comment = FTS(sensor_loc))   #searching for activity with location loc_name\n",
    "    print(\"AL: \",Act)\n",
    "    Act_name=Act[0].name                    # getting only the activity name as string\n",
    "    \n",
    "    sensor_present=findSensor(sensor[0].name,freq_list)\n",
    "    \n",
    "    if Activity_name != Act_name and sensor_present==0 and i+1!=len(df):\n",
    "#         print(\"$$$$$\")\n",
    "#         if skip>5: \n",
    "            print(\"$$$$$\")\n",
    "            skip=skipSensor(Activity,i)\n",
    "            if skip==1 and skip_count<=5:\n",
    "                #sensr=\n",
    "                skip_count=skip_count+1\n",
    "                print(\"@#$%^&&\",i)\n",
    "                #continue\n",
    "            else:\n",
    "                cut_index=i\n",
    "                f_df=segment(start_index,cut_index,Activity_name,f_df)\n",
    "                sensr=sensor\n",
    "                print(\"Sensor : \",sensr)\n",
    "                ind=i\n",
    "                print(\"SKipping sensor: \", ind)\n",
    "                pAct=Activity_name\n",
    "                print(\"Previous Avtivity: \", pAct)\n",
    "                flag=0\n",
    "                continue\n",
    "        \n",
    "    if i+1==len(df) :\n",
    "        print(\"!!!!\")\n",
    "        cut_index=i+1\n",
    "        f_df=segment(start_index,cut_index,Activity_name,f_df)\n",
    "        \n",
    "    else:\n",
    "        print(\"@@@@@\",i)\n",
    "        flag=1\n",
    "        \n",
    "print(f_df[:40])\n",
    "f_df.to_csv('Segment.csv')\n",
    "\n",
    "# get the end time\n",
    "et = time.time()\n",
    "\n",
    "# get the execution time\n",
    "elapsed_time = et - st\n",
    "print('Execution time:', elapsed_time, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
